---
title: dbt Testing & Documentation
date: 2025-10-17
tags: [dbt, testing, documentation, data-quality, schema-tests, singular-tests, dbt-expectations, data-engineering]
status: active
learning_phase: "Advanced Queries (Analytical)"
source: https://docs.getdbt.com/docs/build/tests
---

**Created:** 2025-10-17
**Last Updated:** 2025-10-17
**Status:** âœ… Complete

---

## Overview

Testing and documentation are first-class citizens in dbt, transforming data quality from an afterthought into a systematic, automated practice. Tests validate data assumptions, catch errors early, and serve as executable documentation. Generated documentation provides an always-up-to-date view of your data pipeline with interactive lineage graphs.

**Key Value Proposition:** Catch data quality issues before they reach dashboards, and maintain living documentation that evolves with your code.

---

## 4.1 Testing Philosophy

### Why Test Data?

**Traditional Software Testing:** Tests validate that code behaves correctly.

**Data Testing:** Tests validate that data meets expectations.

```sql
-- Code works perfectly...
SELECT
    customer_id,
    SUM(order_total) AS lifetime_value
FROM orders
GROUP BY customer_id

-- ...but data might be broken:
-- - Duplicate customer_ids
-- - NULL values in customer_id
-- - Negative order totals
-- - Orders without matching customers
```

**dbt Tests Answer:**
- Is this customer_id unique?
- Are there NULL values?
- Do all orders have valid customers?
- Are totals within expected ranges?

---

### Types of Tests in dbt

| Test Type | Scope | Definition Location | Use Case |
|-----------|-------|---------------------|----------|
| **Schema Tests** | Column/Model | YAML files | Standard validations (unique, not_null) |
| **Singular Tests** | Custom SQL | .sql files in tests/ | Complex business logic |
| **Generic Tests** | Reusable | Macros | Custom reusable validations |
| **Source Freshness** | Sources | sources.yml | Data pipeline monitoring |

---

## 4.2 Schema Tests (Generic Tests)

### Built-In Tests

dbt provides four built-in schema tests:

1. **unique** - No duplicates
2. **not_null** - No NULL values
3. **accepted_values** - Column contains only specified values
4. **relationships** - Foreign key integrity

---

### 1. Unique Test

**Purpose:** Ensure column has no duplicate values (primary key validation).

```yaml
# models/staging/stg_customers.yml
version: 2

models:
  - name: stg_customers
    description: "Cleaned customer data from raw source"
    columns:
      - name: customer_id
        description: "Unique identifier for customer"
        tests:
          - unique
```

**Generated SQL:**
```sql
-- This query should return 0 rows
SELECT
    customer_id,
    COUNT(*) AS n_records
FROM analytics.stg_customers
GROUP BY customer_id
HAVING COUNT(*) > 1
```

**Test Passes:** Query returns 0 rows (no duplicates)
**Test Fails:** Query returns rows (duplicates exist)

---

### 2. Not Null Test

**Purpose:** Ensure column has no NULL values.

```yaml
models:
  - name: stg_orders
    columns:
      - name: order_id
        tests:
          - not_null
      - name: customer_id
        tests:
          - not_null
      - name: order_date
        tests:
          - not_null
```

**Generated SQL:**
```sql
-- This query should return 0 rows
SELECT *
FROM analytics.stg_orders
WHERE order_id IS NULL
   OR customer_id IS NULL
   OR order_date IS NULL
```

---

### 3. Accepted Values Test

**Purpose:** Ensure column contains only specified values (enum validation).

```yaml
models:
  - name: stg_orders
    columns:
      - name: order_status
        tests:
          - accepted_values:
              values: ['pending', 'processing', 'shipped', 'delivered', 'cancelled']
```

**Generated SQL:**
```sql
-- This query should return 0 rows
SELECT *
FROM analytics.stg_orders
WHERE order_status NOT IN ('pending', 'processing', 'shipped', 'delivered', 'cancelled')
```

**Use Cases:**
- Status fields (active/inactive, pending/complete)
- Payment methods (credit_card, paypal, bank_transfer)
- Geographic regions (US, CA, UK, EU)
- Product categories

---

### 4. Relationships Test

**Purpose:** Ensure foreign key integrity (referential integrity).

```yaml
models:
  - name: stg_orders
    columns:
      - name: customer_id
        description: "References stg_customers.customer_id"
        tests:
          - relationships:
              to: ref('stg_customers')
              field: customer_id
```

**Generated SQL:**
```sql
-- This query should return 0 rows (orphaned orders)
SELECT *
FROM analytics.stg_orders
WHERE customer_id NOT IN (
    SELECT customer_id
    FROM analytics.stg_customers
)
```

**Use Cases:**
- Orders â†’ Customers
- Order Items â†’ Orders
- Order Items â†’ Products
- Payments â†’ Orders

---

### Combining Multiple Tests

```yaml
version: 2

models:
  - name: stg_customers
    description: "Staging layer for customer data"
    columns:
      - name: customer_id
        description: "Primary key for customers"
        tests:
          - unique
          - not_null

      - name: email
        description: "Customer email address"
        tests:
          - not_null

      - name: customer_status
        description: "Current customer status"
        tests:
          - accepted_values:
              values: ['active', 'inactive', 'suspended']

      - name: created_at
        description: "Timestamp when customer was created"
        tests:
          - not_null

  - name: stg_orders
    description: "Staging layer for order data"
    columns:
      - name: order_id
        description: "Primary key for orders"
        tests:
          - unique
          - not_null

      - name: customer_id
        description: "Foreign key to customers"
        tests:
          - not_null
          - relationships:
              to: ref('stg_customers')
              field: customer_id

      - name: order_status
        tests:
          - accepted_values:
              values: ['pending', 'processing', 'shipped', 'delivered', 'cancelled']
```

---

### Test Configuration

```yaml
models:
  - name: stg_orders
    columns:
      - name: order_id
        tests:
          - unique:
              config:
                severity: error  # error (default) or warn
                error_if: ">5"   # Fail if more than 5 failures
                warn_if: ">0"    # Warn if any failures
```

**Severity Levels:**
- **error** (default): Test failure stops execution, returns non-zero exit code
- **warn**: Test failure logs warning, continues execution

**Use Cases for warn:**
- Non-critical validations
- Tests with known failures being addressed
- Gradual rollout of new tests

```bash
# Run tests and see warnings
dbt test

# Treat warnings as errors
dbt test --warn-error
```

---

### Model-Level Tests

```yaml
models:
  - name: customer_lifetime_value
    description: "Customer LTV calculation"
    tests:
      - dbt_utils.expression_is_true:
          expression: "lifetime_value >= 0"
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - customer_id
            - calculation_date
```

---

## 4.3 Singular Tests (Custom Data Tests)

### What are Singular Tests?

**Definition:** Custom SQL queries in the `tests/` directory. Test passes if query returns zero rows.

```sql
-- tests/assert_valid_order_totals.sql

-- Test fails if this query returns any rows
SELECT
    order_id,
    order_total,
    line_items_total
FROM {{ ref('stg_orders') }}
WHERE order_total <> line_items_total
```

**Naming Convention:** `assert_<condition>.sql` or `test_<description>.sql`

---

### Example: Business Logic Validation

```sql
-- tests/assert_customer_has_valid_email.sql

SELECT
    customer_id,
    email
FROM {{ ref('stg_customers') }}
WHERE email NOT LIKE '%@%.%'
   OR email IS NULL
```

**Use Case:** Email format validation

---

### Example: Cross-Model Consistency

```sql
-- tests/assert_order_payment_amounts_match.sql

WITH order_totals AS (
    SELECT
        order_id,
        SUM(order_total) AS total_from_orders
    FROM {{ ref('stg_orders') }}
    GROUP BY order_id
),

payment_totals AS (
    SELECT
        order_id,
        SUM(amount) AS total_from_payments
    FROM {{ ref('stg_payments') }}
    GROUP BY order_id
)

SELECT
    o.order_id,
    o.total_from_orders,
    p.total_from_payments
FROM order_totals o
INNER JOIN payment_totals p
    ON o.order_id = p.order_id
WHERE ABS(o.total_from_orders - p.total_from_payments) > 0.01
```

**Use Case:** Financial reconciliation

---

### Example: Temporal Logic

```sql
-- tests/assert_order_dates_before_ship_dates.sql

SELECT
    order_id,
    order_date,
    ship_date
FROM {{ ref('stg_orders') }}
WHERE ship_date < order_date
```

**Use Case:** Validate date sequencing

---

### Example: Statistical Outliers

```sql
-- tests/assert_no_extreme_outliers_in_order_totals.sql

WITH stats AS (
    SELECT
        AVG(order_total) AS mean_order_total,
        STDDEV(order_total) AS stddev_order_total
    FROM {{ ref('stg_orders') }}
),

outliers AS (
    SELECT
        o.order_id,
        o.order_total,
        s.mean_order_total,
        s.stddev_order_total
    FROM {{ ref('stg_orders') }} o
    CROSS JOIN stats s
    WHERE ABS(o.order_total - s.mean_order_total) > (3 * s.stddev_order_total)
)

SELECT * FROM outliers
```

**Use Case:** Detect data anomalies

---

### Singular Test Best Practices

1. **Descriptive Names**
   ```
   âœ… assert_revenue_equals_quantity_times_price.sql
   âŒ test1.sql
   ```

2. **Add Comments**
   ```sql
   -- Test ensures that calculated revenue matches
   -- the product of quantity and unit price.
   -- Created: 2024-01-15
   -- Owner: finance-team
   ```

3. **Use CTEs for Clarity**
   ```sql
   WITH calculated_revenue AS (...),
        expected_revenue AS (...)
   SELECT ... FROM calculated_revenue
   ```

4. **Consider Severity**
   ```sql
   -- tests/assert_recent_orders_exist.sql
   {{ config(severity='warn') }}

   SELECT CURRENT_DATE AS test_date
   WHERE NOT EXISTS (
       SELECT 1 FROM {{ ref('stg_orders') }}
       WHERE order_date >= CURRENT_DATE - 1
   )
   ```

---

## 4.4 Generic Tests (Reusable Custom Tests)

### Creating Custom Generic Tests

**Definition:** Reusable tests defined as macros in `tests/generic/` or `macros/`.

```sql
-- tests/generic/test_positive_values.sql

{% test positive_values(model, column_name) %}

SELECT *
FROM {{ model }}
WHERE {{ column_name }} <= 0

{% endtest %}
```

**Usage in YAML:**
```yaml
models:
  - name: stg_orders
    columns:
      - name: order_total
        tests:
          - positive_values

      - name: quantity
        tests:
          - positive_values
```

---

### Example: Date Range Test

```sql
-- tests/generic/test_date_range.sql

{% test date_range(model, column_name, min_date, max_date) %}

SELECT *
FROM {{ model }}
WHERE {{ column_name }} < '{{ min_date }}'
   OR {{ column_name }} > '{{ max_date }}'

{% endtest %}
```

**Usage:**
```yaml
models:
  - name: stg_orders
    columns:
      - name: order_date
        tests:
          - date_range:
              min_date: '2020-01-01'
              max_date: '2025-12-31'
```

---

### Example: Pattern Matching Test

```sql
-- tests/generic/test_matches_pattern.sql

{% test matches_pattern(model, column_name, pattern) %}

SELECT *
FROM {{ model }}
WHERE NOT REGEXP_LIKE({{ column_name }}, '{{ pattern }}')

{% endtest %}
```

**Usage:**
```yaml
models:
  - name: stg_customers
    columns:
      - name: phone_number
        tests:
          - matches_pattern:
              pattern: '^\\d{3}-\\d{3}-\\d{4}$'
```

---

## 4.5 dbt Expectations Package

### What is dbt Expectations?

**Definition:** A dbt package that brings Great Expectations-style tests to dbt with 50+ additional generic tests.

```yaml
# packages.yml
packages:
  - package: calogica/dbt_expectations
    version: 0.10.0
```

```bash
dbt deps  # Install package
```

---

### Popular dbt_expectations Tests

#### 1. expect_column_values_to_be_between

```yaml
models:
  - name: stg_products
    columns:
      - name: price
        tests:
          - dbt_expectations.expect_column_values_to_be_between:
              min_value: 0
              max_value: 10000
```

---

#### 2. expect_column_values_to_match_regex

```yaml
models:
  - name: stg_customers
    columns:
      - name: email
        tests:
          - dbt_expectations.expect_column_values_to_match_regex:
              regex: "^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$"
```

---

#### 3. expect_column_values_to_be_in_set

```yaml
models:
  - name: stg_orders
    columns:
      - name: payment_method
        tests:
          - dbt_expectations.expect_column_values_to_be_in_set:
              value_set: ['credit_card', 'debit_card', 'paypal', 'bank_transfer']
```

---

#### 4. expect_table_row_count_to_be_between

```yaml
models:
  - name: stg_daily_orders
    tests:
      - dbt_expectations.expect_table_row_count_to_be_between:
          min_value: 100
          max_value: 10000
```

---

#### 5. expect_column_pair_values_to_be_equal

```yaml
models:
  - name: stg_orders
    tests:
      - dbt_expectations.expect_column_pair_values_to_be_equal:
          column_A: calculated_total
          column_B: stored_total
```

---

#### 6. expect_column_values_to_be_increasing

```yaml
models:
  - name: stg_events
    columns:
      - name: event_timestamp
        tests:
          - dbt_expectations.expect_column_values_to_be_increasing:
              sort_column: event_id
```

---

### Comprehensive Test Suite Example

```yaml
version: 2

models:
  - name: stg_customers
    description: "Customer staging table with comprehensive data quality tests"
    tests:
      # Table-level tests
      - dbt_expectations.expect_table_row_count_to_be_between:
          min_value: 1000
          max_value: 1000000

      - dbt_expectations.expect_table_columns_to_match_ordered_list:
          column_list: ["customer_id", "email", "first_name", "last_name", "created_at"]

    columns:
      - name: customer_id
        description: "Primary key"
        tests:
          - unique
          - not_null

      - name: email
        description: "Customer email address"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_unique
          - dbt_expectations.expect_column_values_to_match_regex:
              regex: "^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$"

      - name: created_at
        description: "Customer creation timestamp"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_between:
              min_value: "2020-01-01"
              max_value: "2025-12-31"

      - name: lifetime_value
        description: "Total customer spend"
        tests:
          - dbt_expectations.expect_column_values_to_be_between:
              min_value: 0
              max_value: 1000000
          - dbt_expectations.expect_column_mean_to_be_between:
              min_value: 100
              max_value: 5000
```

---

## 4.6 Source Freshness Testing

### What is Source Freshness?

**Definition:** Monitoring that validates source data is being updated on schedule.

```yaml
# models/staging/sources.yml
version: 2

sources:
  - name: raw
    database: production
    schema: raw_data

    # Default freshness for all tables
    freshness:
      warn_after: {count: 12, period: hour}
      error_after: {count: 24, period: hour}

    tables:
      - name: customers
        description: "Raw customer data from Fivetran"
        loaded_at_field: _fivetran_synced
        freshness:
          warn_after: {count: 6, period: hour}
          error_after: {count: 12, period: hour}

      - name: orders
        description: "Raw order data from Fivetran"
        loaded_at_field: _fivetran_synced
        freshness:
          warn_after: {count: 1, period: hour}
          error_after: {count: 2, period: hour}

      - name: products
        description: "Product catalog (updated weekly)"
        loaded_at_field: updated_at
        freshness:
          warn_after: {count: 7, period: day}
          error_after: {count: 14, period: day}
```

---

### Running Freshness Checks

```bash
# Check freshness for all sources
dbt source freshness

# Check specific source
dbt source freshness --select source:raw

# Output freshness to JSON
dbt source freshness --output target/freshness.json
```

**Example Output:**
```
12:30:45 | Concurrency: 4 threads
12:30:47 | 1 of 3 PASS freshness of raw.customers ............... [PASS in 0.45s]
12:30:47 | 2 of 3 WARN freshness of raw.orders ................. [WARN in 0.52s]
12:30:48 | 3 of 3 PASS freshness of raw.products ............... [PASS in 0.38s]

Completed with 1 warning:

Warning in source:raw.orders (models/staging/sources.yml)
Got 3 results, configured to warn at 1
```

---

### Freshness in CI/CD

```yaml
# .github/workflows/dbt_freshness.yml
name: Check Source Freshness

on:
  schedule:
    - cron: '0 */6 * * *'  # Every 6 hours

jobs:
  check-freshness:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: dbt source freshness
        run: |
          dbt source freshness
          if [ $? -ne 0 ]; then
            # Send alert to Slack/PagerDuty
            curl -X POST $SLACK_WEBHOOK -d "Source data is stale!"
          fi
```

---

### Best Practices for Source Freshness

1. **Set Appropriate Thresholds**
   ```yaml
   # Real-time data (updated every 15 mins)
   freshness:
     warn_after: {count: 30, period: minute}
     error_after: {count: 1, period: hour}

   # Daily batch (updated nightly)
   freshness:
     warn_after: {count: 26, period: hour}
     error_after: {count: 30, period: hour}

   # Weekly data
   freshness:
     warn_after: {count: 8, period: day}
     error_after: {count: 10, period: day}
   ```

2. **Use Correct Timestamp Column**
   ```yaml
   loaded_at_field: _fivetran_synced  # For Fivetran
   loaded_at_field: _airbyte_emitted_at  # For Airbyte
   loaded_at_field: updated_at  # For application tables
   ```

3. **Monitor in Production**
   - Run freshness checks before dbt runs
   - Alert on failures
   - Track SLA compliance

---

## 4.7 Documentation

### Documentation in YAML

```yaml
# models/staging/stg_customers.yml
version: 2

models:
  - name: stg_customers
    description: |
      Cleaned and standardized customer data from the raw CRM system.

      This model:
      - Removes test customers (email like '%@test.com')
      - Uppercases names for consistency
      - Standardizes phone number format
      - Adds customer tier based on lifetime value

      **Refresh Schedule:** Every 6 hours
      **Owner:** Analytics Team

    columns:
      - name: customer_id
        description: |
          Unique identifier for each customer. Primary key.

          **Source:** raw.customers.id
        tests:
          - unique
          - not_null

      - name: email
        description: |
          Customer email address (lowercase).

          Used as primary contact method and for marketing campaigns.
        tests:
          - not_null
          - unique

      - name: first_name
        description: "Customer first name (uppercased)"

      - name: last_name
        description: "Customer last name (uppercased)"

      - name: customer_tier
        description: |
          Customer tier based on lifetime value:
          - gold: >$10,000
          - silver: $5,000-$10,000
          - bronze: $1,000-$5,000
          - standard: <$1,000
        tests:
          - accepted_values:
              values: ['gold', 'silver', 'bronze', 'standard']
```

---

### Documenting Sources

```yaml
# models/staging/sources.yml
version: 2

sources:
  - name: raw
    description: "Raw data synced from production database via Fivetran"
    database: production
    schema: raw_data

    tables:
      - name: customers
        description: |
          Customer master table from the CRM system.

          **Update Frequency:** Real-time (change data capture)
          **Row Count:** ~500,000
          **Owner:** CRM Team

        columns:
          - name: id
            description: "Primary key from CRM system"

          - name: email
            description: "Customer email (unique)"

          - name: created_at
            description: "Timestamp when customer was created in CRM"

          - name: _fivetran_synced
            description: "Timestamp when Fivetran last synced this row"
```

---

### Inline Documentation

```sql
-- models/marts/customer_lifetime_value.sql

{{
    config(
        materialized='table',
        description='Customer lifetime value calculation including all completed orders'
    )
}}

WITH customers AS (
    -- Source: Staging layer customer data
    -- Contains deduplicated, cleaned customer records
    SELECT * FROM {{ ref('stg_customers') }}
),

orders AS (
    -- Source: Staging layer order data
    -- Only includes orders with 'completed' status
    SELECT * FROM {{ ref('stg_orders') }}
    WHERE order_status = 'completed'
),

customer_metrics AS (
    SELECT
        c.customer_id,
        c.first_name,
        c.last_name,
        c.email,

        -- Order metrics
        COUNT(DISTINCT o.order_id) AS total_orders,
        SUM(o.order_total) AS lifetime_value,
        AVG(o.order_total) AS avg_order_value,

        -- Temporal metrics
        MIN(o.order_date) AS first_order_date,
        MAX(o.order_date) AS most_recent_order_date,

        -- Calculate customer lifespan in days
        DATEDIFF('day', MIN(o.order_date), MAX(o.order_date)) AS customer_lifespan_days

    FROM customers c
    LEFT JOIN orders o
        ON c.customer_id = o.customer_id
    GROUP BY 1, 2, 3, 4
)

SELECT * FROM customer_metrics
```

---

### Generating Documentation

```bash
# Generate documentation
dbt docs generate

# Serve documentation site
dbt docs serve

# By default, serves on http://localhost:8080
```

**What Gets Generated:**
1. **Project Overview** - Models, sources, tests
2. **Lineage Graph** - Interactive DAG visualization
3. **Model Details** - SQL code, descriptions, columns
4. **Test Results** - Pass/fail status
5. **Source Freshness** - Last update times
6. **Compiled SQL** - What actually runs in warehouse

---

### Documentation Site Features

#### 1. Interactive Lineage Graph

- Visual representation of model dependencies
- Click nodes to see model details
- Trace data flow from source â†’ marts
- Identify downstream impacts

#### 2. Model Details Page

For each model:
- Description
- Compiled SQL
- Column list with descriptions
- Test results
- Materialization type
- Dependencies (upstream/downstream)

#### 3. Search Functionality

- Search models by name
- Search columns by name
- Search descriptions

#### 4. Source Documentation

- Source table definitions
- Freshness checks
- Column documentation

---

### Custom Overview Documentation

```md
<!-- models/overview.md -->

# Analytics Data Warehouse

Welcome to the XYZ Company analytics data warehouse documentation.

## Architecture

Our data warehouse follows a medallion architecture:

- **Bronze (Staging)**: Raw data from source systems
- **Silver (Intermediate)**: Cleaned and joined data
- **Gold (Marts)**: Business-ready analytics tables

## Key Models

### Customer Analytics
- `customer_lifetime_value` - Total revenue per customer
- `customer_cohorts` - Monthly customer cohorts
- `customer_churn` - Churn prediction model

### Product Analytics
- `product_performance` - Sales metrics by product
- `inventory_forecast` - Inventory predictions

## Getting Help

Contact the Analytics Team: analytics@company.com
```

```yaml
# dbt_project.yml
name: 'my_project'

# Point to custom overview
docs-paths: ["models"]
```

---

### Documentation Best Practices

1. **Document WHY, Not Just WHAT**
   ```yaml
   # âŒ Not helpful
   description: "Customer table"

   # âœ… Helpful
   description: |
     Active customers from the CRM system, filtered to remove:
     - Test accounts
     - Deleted customers
     - Duplicate records

     Updated every 6 hours via Fivetran.
   ```

2. **Use Markdown Formatting**
   ```yaml
   description: |
     ## Customer Tiers

     Customers are segmented into tiers based on lifetime value:

     | Tier | LTV Range | Benefits |
     |------|-----------|----------|
     | Gold | >$10k | Premium support |
     | Silver | $5k-$10k | Priority shipping |
     | Bronze | $1k-$5k | Standard |
   ```

3. **Link to External Resources**
   ```yaml
   description: |
     Customer data from Salesforce CRM.

     [CRM Documentation](https://company.atlassian.net/wiki/crm)
     [Field Definitions](https://company.atlassian.net/wiki/crm-fields)
   ```

4. **Document Calculations**
   ```yaml
   - name: customer_ltv_predicted
     description: |
       Predicted lifetime value using linear regression.

       **Formula:**
       `LTV = (avg_order_value * purchase_frequency * customer_lifespan)`

       **Model:** Trained monthly on 12-month cohort data
       **Accuracy:** RMSE of $245 on test set
   ```

5. **Keep Docs Up-to-Date**
   - Update descriptions when logic changes
   - Review docs in pull requests
   - Run `dbt docs generate` in CI/CD

---

## 4.8 Testing Strategies

### Test Coverage Pyramid

```
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Singular  â”‚  â† Complex business logic (few)
         â”‚    Tests    â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚   Generic   â”‚  â† Reusable validations (moderate)
         â”‚    Tests    â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚   Schema    â”‚  â† Standard checks (many)
         â”‚    Tests    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Strategy:**
- Many schema tests (unique, not_null)
- Moderate generic tests (dbt_expectations)
- Few singular tests (complex business rules)

---

### Critical vs Non-Critical Tests

```yaml
# Critical tests (block deployment)
models:
  - name: fct_orders
    columns:
      - name: order_id
        tests:
          - unique:
              config:
                severity: error  # Default
          - not_null:
              config:
                severity: error

# Non-critical tests (warn only)
  - name: stg_customers
    columns:
      - name: phone_number
        tests:
          - matches_pattern:
              pattern: '^\\d{3}-\\d{3}-\\d{4}$'
              config:
                severity: warn  # Don't block on format issues
```

---

### Testing in CI/CD

```yaml
# .github/workflows/dbt_ci.yml
name: dbt CI

on:
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install dbt
        run: pip install dbt-snowflake

      - name: Run dbt models
        run: dbt run --select state:modified+ --state target/

      - name: Run dbt tests
        run: dbt test --select state:modified+ --state target/

      - name: Check source freshness
        run: dbt source freshness
```

---

### Test Selection

```bash
# Test specific model
dbt test --select stg_customers

# Test model and upstream dependencies
dbt test --select +stg_customers

# Test by tag
dbt test --select tag:critical

# Test only schema tests
dbt test --select test_type:schema

# Test only singular tests
dbt test --select test_type:singular

# Run tests after build
dbt build --select stg_customers  # Runs model + tests
```

---

### Performance Testing

```sql
-- tests/performance/assert_customer_ltv_runtime.sql

-- Ensure this query completes in under 5 seconds
-- Run with: dbt test --select assert_customer_ltv_runtime

{{ config(
    severity='warn',
    tags=['performance']
) }}

WITH start_time AS (
    SELECT CURRENT_TIMESTAMP AS start_ts
),

run_query AS (
    SELECT COUNT(*) AS row_count
    FROM {{ ref('customer_lifetime_value') }}
),

end_time AS (
    SELECT CURRENT_TIMESTAMP AS end_ts
)

SELECT
    s.start_ts,
    e.end_ts,
    DATEDIFF('second', s.start_ts, e.end_ts) AS runtime_seconds
FROM start_time s
CROSS JOIN end_time e
WHERE DATEDIFF('second', s.start_ts, e.end_ts) > 5
```

---

## ðŸŽ¯ Best Practices

### Testing

1. **Test Primary Keys Always**
   - Every model should test unique + not_null on PK
   - Use `dbt_utils.unique_combination_of_columns` for composite keys

2. **Test Foreign Keys**
   - Use `relationships` test for all foreign keys
   - Catch orphaned records early

3. **Test Business Logic**
   - Write singular tests for critical calculations
   - Document test rationale

4. **Use Appropriate Severity**
   - `error` for data quality issues
   - `warn` for nice-to-have validations

5. **Test Incrementally**
   - Add tests as you add models
   - Don't retrofit all tests at once

6. **Monitor Test Performance**
   - Slow tests slow down CI/CD
   - Optimize or sample large tables

### Documentation

1. **Document as You Go**
   - Add descriptions when creating models
   - Don't leave it for later

2. **Focus on WHY**
   - Explain business logic, not SQL syntax
   - Document assumptions and edge cases

3. **Keep It Current**
   - Review docs in pull requests
   - Deprecate outdated models

4. **Use Consistent Style**
   - Establish documentation standards
   - Use templates for common patterns

5. **Generate Regularly**
   - Run `dbt docs generate` in CI/CD
   - Host docs site for team access

---

## ðŸ”— Related Notes

- [[03. dbt Models & Materializations|Previous: Models & Materializations]]
- [[05. dbt Deployment, Orchestration & Integration|Next: Deployment & Orchestration]]
- [[01. dbt Fundamentals - Introduction & Core Concepts|dbt Fundamentals]]
- [[README|Project Overview]]

---

## ðŸ“š Key Takeaways

1. **Tests are executable documentation** - They codify data assumptions
2. **Four built-in tests** - unique, not_null, accepted_values, relationships
3. **Singular tests for complex logic** - Custom SQL in tests/ directory
4. **Generic tests for reusability** - Create custom reusable tests
5. **dbt_expectations adds 50+ tests** - Great Expectations for dbt
6. **Source freshness monitors data pipelines** - Catch upstream issues
7. **Documentation is auto-generated** - Always up-to-date with code
8. **Test in CI/CD** - Catch issues before production
9. **Use appropriate severity** - error vs warn based on criticality
10. **Document WHY, not just WHAT** - Explain business context

---

**Last Updated:** 2025-10-17
**Chapter Status:** âœ… Complete
