---
title: Logging & Monitoring for Data Pipelines
date: 2025-10-16
tags: [python, logging, monitoring, observability, debugging, data-engineering, best-practices]
status: active
learning_phase: "Best Practices (Operations)"
---

**Created:** 2025-10-16
**Last Updated:** 2025-10-16
**Status:** ‚úÖ Complete

---

## Overview

**Effective logging is the cornerstone of maintainable and reliable data pipelines** - It enables monitoring, debugging, and understanding system behavior in production. This note covers comprehensive logging and monitoring strategies for data engineering.

**Key Principle:** Logs should be structured, contextual, and actionable. In development, optimize for readability. In production, optimize for machine parsing and observability tools.

---

## Why Logging Matters for Data Engineering

### The Challenge of Distributed Systems

```
Data Pipeline = Multiple Systems + Async Processes + Scale
Without Logging = Debugging Nightmare
```

**Common scenarios requiring logging:**
- Pipeline failures at 3 AM
- Data quality issues discovered downstream
- Performance degradation over time
- Debugging customer-reported issues
- Audit trails for compliance
- Understanding system behavior patterns

### Benefits of Good Logging

1. **Faster debugging** - Quickly identify root causes
2. **Proactive monitoring** - Catch issues before users do
3. **Audit trails** - Track data lineage and changes
4. **Performance insights** - Identify bottlenecks
5. **Compliance** - Meet regulatory requirements
6. **System understanding** - Learn how pipelines behave

---

## Python Logging Fundamentals

### Log Levels - When to Use Each

| Level | Use Case | Example |
|-------|----------|---------|
| **DEBUG** | Detailed diagnostic info | "Processing row 1234 with customer_id=5678" |
| **INFO** | Confirmation of expected behavior | "ETL job started processing 10,000 records" |
| **WARNING** | Unexpected but handled situation | "Rate limit reached, retrying in 60s" |
| **ERROR** | Serious problem, function failed | "Failed to connect to database after 3 retries" |
| **CRITICAL** | Fatal error, system may crash | "Out of memory, terminating process" |

---

### Basic Logging Setup

```python
import logging

# Configure logging (do this once at application start)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# Create logger for your module
logger = logging.getLogger(__name__)

# Log messages
logger.debug("This is detailed debug information")
logger.info("ETL pipeline started")
logger.warning("Retry attempt 2 of 3")
logger.error("Failed to fetch data from API")
logger.critical("System out of memory")
```

**Output:**
```
2025-10-16 10:30:45 - __main__ - INFO - ETL pipeline started
2025-10-16 10:30:46 - __main__ - WARNING - Retry attempt 2 of 3
2025-10-16 10:30:47 - __main__ - ERROR - Failed to fetch data from API
```

---

### Advanced Logging Configuration

```python
import logging
import sys
from pathlib import Path

def setup_logging(log_level=logging.INFO, log_file=None):
    """Configure logging with both file and console handlers"""

    # Create logger
    logger = logging.getLogger()
    logger.setLevel(log_level)

    # Clear existing handlers
    logger.handlers.clear()

    # Create formatter
    formatter = logging.Formatter(
        fmt='%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )

    # Console handler (stdout)
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(log_level)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

    # File handler (if specified)
    if log_file:
        Path(log_file).parent.mkdir(parents=True, exist_ok=True)
        file_handler = logging.FileHandler(log_file)
        file_handler.setLevel(log_level)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)

    return logger

# Usage
logger = setup_logging(
    log_level=logging.INFO,
    log_file='logs/pipeline.log'
)

logger.info("Logging configured successfully")
```

---

## Structured Logging - The Modern Approach

### Why Structured Logging?

**Traditional logging (unstructured):**
```python
logger.info(f"Processed {row_count} rows for customer {customer_id} in {duration}s")
```

**Output:**
```
2025-10-16 10:30:45 - INFO - Processed 1000 rows for customer 12345 in 5.3s
```

**Problem:** Hard to query, parse, and aggregate.

---

**Structured logging (JSON):**
```python
import json
import logging

logger.info(json.dumps({
    "event": "data_processed",
    "row_count": 1000,
    "customer_id": 12345,
    "duration_seconds": 5.3,
    "timestamp": "2025-10-16T10:30:45Z"
}))
```

**Output:**
```json
{"event": "data_processed", "row_count": 1000, "customer_id": 12345, "duration_seconds": 5.3, "timestamp": "2025-10-16T10:30:45Z"}
```

**Benefits:** Easy to query, aggregate, and visualize in logging platforms (Datadog, Splunk, CloudWatch).

---

### Using python-json-logger

```python
import logging
from pythonjsonlogger import jsonlogger

# Create JSON formatter
formatter = jsonlogger.JsonFormatter(
    '%(asctime)s %(name)s %(levelname)s %(message)s'
)

# Setup handler
handler = logging.StreamHandler()
handler.setFormatter(formatter)

# Configure logger
logger = logging.getLogger()
logger.addHandler(handler)
logger.setLevel(logging.INFO)

# Log with extra context
logger.info(
    "Data processing completed",
    extra={
        "job_id": "etl-2025-10-16",
        "rows_processed": 10000,
        "duration_seconds": 45.2,
        "status": "success"
    }
)
```

**Output (JSON):**
```json
{
  "asctime": "2025-10-16 10:30:45",
  "name": "root",
  "levelname": "INFO",
  "message": "Data processing completed",
  "job_id": "etl-2025-10-16",
  "rows_processed": 10000,
  "duration_seconds": 45.2,
  "status": "success"
}
```

---

## Contextual Logging - Adding Rich Metadata

### Using LoggerAdapter for Context

```python
import logging

class ContextAdapter(logging.LoggerAdapter):
    """Add contextual information to all log messages"""

    def process(self, msg, kwargs):
        # Add context from self.extra to all messages
        return f"[{self.extra['job_id']}] {msg}", kwargs

# Create logger with context
logger = logging.getLogger(__name__)
contextual_logger = ContextAdapter(
    logger,
    extra={'job_id': 'etl-2025-10-16', 'environment': 'production'}
)

# All logs now include context
contextual_logger.info("Starting data extraction")
contextual_logger.info("Processing batch 1 of 10")
contextual_logger.error("API request failed")

# Output:
# [etl-2025-10-16] Starting data extraction
# [etl-2025-10-16] Processing batch 1 of 10
# [etl-2025-10-16] API request failed
```

---

### Context Manager for Scoped Logging

```python
import logging
from contextlib import contextmanager
import time

logger = logging.getLogger(__name__)

@contextmanager
def log_operation(operation_name, **context):
    """Log operation with timing and context"""
    start_time = time.time()

    logger.info(
        f"Starting {operation_name}",
        extra={"operation": operation_name, "event": "start", **context}
    )

    try:
        yield
        duration = time.time() - start_time
        logger.info(
            f"Completed {operation_name}",
            extra={
                "operation": operation_name,
                "event": "complete",
                "duration_seconds": round(duration, 2),
                "status": "success",
                **context
            }
        )
    except Exception as e:
        duration = time.time() - start_time
        logger.error(
            f"Failed {operation_name}: {str(e)}",
            extra={
                "operation": operation_name,
                "event": "failed",
                "duration_seconds": round(duration, 2),
                "status": "error",
                "error": str(e),
                **context
            },
            exc_info=True
        )
        raise

# Usage
with log_operation("extract_customer_data", source="postgres", table="customers"):
    # Your extraction code
    extract_data()

with log_operation("transform_data", rows=10000):
    # Your transformation code
    transform_data()
```

---

## Data Pipeline Logging Patterns

### ETL Job Logging Template

```python
import logging
import time
from typing import Dict, Any

logger = logging.getLogger(__name__)

class ETLJobLogger:
    """Standardized logging for ETL jobs"""

    def __init__(self, job_name: str, job_id: str):
        self.job_name = job_name
        self.job_id = job_id
        self.start_time = None
        self.metrics = {
            'rows_extracted': 0,
            'rows_transformed': 0,
            'rows_loaded': 0,
            'errors': 0
        }

    def log_start(self, **kwargs):
        """Log job start"""
        self.start_time = time.time()
        logger.info(
            f"ETL job started: {self.job_name}",
            extra={
                "event": "job_start",
                "job_name": self.job_name,
                "job_id": self.job_id,
                **kwargs
            }
        )

    def log_extract(self, row_count: int, source: str):
        """Log extraction phase"""
        self.metrics['rows_extracted'] = row_count
        logger.info(
            f"Extracted {row_count} rows from {source}",
            extra={
                "event": "extract_complete",
                "job_id": self.job_id,
                "rows_extracted": row_count,
                "source": source
            }
        )

    def log_transform(self, row_count_before: int, row_count_after: int):
        """Log transformation phase"""
        self.metrics['rows_transformed'] = row_count_after
        filtered = row_count_before - row_count_after

        logger.info(
            f"Transformed data: {row_count_before} -> {row_count_after} rows",
            extra={
                "event": "transform_complete",
                "job_id": self.job_id,
                "rows_input": row_count_before,
                "rows_output": row_count_after,
                "rows_filtered": filtered
            }
        )

    def log_load(self, row_count: int, destination: str):
        """Log load phase"""
        self.metrics['rows_loaded'] = row_count
        logger.info(
            f"Loaded {row_count} rows to {destination}",
            extra={
                "event": "load_complete",
                "job_id": self.job_id,
                "rows_loaded": row_count,
                "destination": destination
            }
        )

    def log_error(self, error: Exception, context: Dict[str, Any] = None):
        """Log error"""
        self.metrics['errors'] += 1
        logger.error(
            f"Error in ETL job: {str(error)}",
            extra={
                "event": "job_error",
                "job_id": self.job_id,
                "error_type": type(error).__name__,
                "error_message": str(error),
                **(context or {})
            },
            exc_info=True
        )

    def log_complete(self, status: str = "success"):
        """Log job completion"""
        duration = time.time() - self.start_time if self.start_time else 0

        logger.info(
            f"ETL job completed: {self.job_name}",
            extra={
                "event": "job_complete",
                "job_name": self.job_name,
                "job_id": self.job_id,
                "status": status,
                "duration_seconds": round(duration, 2),
                **self.metrics
            }
        )

# Usage
job_logger = ETLJobLogger(job_name="daily_customer_sync", job_id="20251016-001")

try:
    job_logger.log_start(schedule="daily", environment="production")

    # Extract
    df = extract_customers_from_db()
    job_logger.log_extract(len(df), source="postgres://customers")

    # Transform
    initial_count = len(df)
    df = clean_and_transform(df)
    job_logger.log_transform(initial_count, len(df))

    # Load
    load_to_warehouse(df)
    job_logger.log_load(len(df), destination="snowflake://analytics")

    job_logger.log_complete(status="success")

except Exception as e:
    job_logger.log_error(e, context={"phase": "extract"})
    job_logger.log_complete(status="failed")
    raise
```

---

### Logging Data Quality Issues

```python
import logging
import pandas as pd

logger = logging.getLogger(__name__)

def validate_and_log_data_quality(df: pd.DataFrame, dataset_name: str):
    """Validate data and log quality metrics"""

    total_rows = len(df)
    issues = []

    # Check for nulls
    null_counts = df.isnull().sum()
    if null_counts.any():
        for col, count in null_counts[null_counts > 0].items():
            pct = (count / total_rows) * 100
            issues.append({
                "type": "null_values",
                "column": col,
                "count": int(count),
                "percentage": round(pct, 2)
            })
            logger.warning(
                f"Null values detected in {col}",
                extra={
                    "event": "data_quality_issue",
                    "dataset": dataset_name,
                    "issue_type": "null_values",
                    "column": col,
                    "null_count": int(count),
                    "null_percentage": round(pct, 2)
                }
            )

    # Check for duplicates
    duplicate_count = df.duplicated().sum()
    if duplicate_count > 0:
        pct = (duplicate_count / total_rows) * 100
        issues.append({
            "type": "duplicates",
            "count": int(duplicate_count),
            "percentage": round(pct, 2)
        })
        logger.warning(
            f"Duplicate rows detected",
            extra={
                "event": "data_quality_issue",
                "dataset": dataset_name,
                "issue_type": "duplicates",
                "duplicate_count": int(duplicate_count),
                "duplicate_percentage": round(pct, 2)
            }
        )

    # Log summary
    logger.info(
        "Data quality check completed",
        extra={
            "event": "data_quality_check",
            "dataset": dataset_name,
            "total_rows": total_rows,
            "issues_found": len(issues),
            "issues": issues
        }
    )

    return issues

# Usage
df = pd.read_csv('customers.csv')
quality_issues = validate_and_log_data_quality(df, "customer_data")
```

---

## Logging Best Practices for Data Engineering

### 1. Never Log Sensitive Data

```python
import logging
import re

logger = logging.getLogger(__name__)

def sanitize_email(email: str) -> str:
    """Mask email for logging"""
    if '@' in email:
        user, domain = email.split('@')
        return f"{user[0]}***@{domain}"
    return "***"

def sanitize_data_for_logging(data: dict) -> dict:
    """Remove/mask sensitive fields before logging"""
    sensitive_fields = ['password', 'ssn', 'credit_card', 'api_key']
    sanitized = data.copy()

    for field in sensitive_fields:
        if field in sanitized:
            sanitized[field] = "***REDACTED***"

    if 'email' in sanitized:
        sanitized['email'] = sanitize_email(sanitized['email'])

    return sanitized

# ‚úÖ Good: Sanitize before logging
customer = {
    'customer_id': 12345,
    'name': 'John Doe',
    'email': 'john.doe@example.com',
    'ssn': '123-45-6789',
    'password': 'secret123'
}

logger.info(
    "Processing customer",
    extra={
        "customer": sanitize_data_for_logging(customer)
    }
)

# ‚ùå Bad: Logging sensitive data
logger.info(f"Processing customer: {customer}")  # DON'T DO THIS!
```

---

### 2. Log at Appropriate Levels

```python
import logging

logger = logging.getLogger(__name__)

def process_batch(records):
    """Example showing appropriate log levels"""

    # INFO: Normal operation milestones
    logger.info(
        "Starting batch processing",
        extra={"batch_size": len(records)}
    )

    # DEBUG: Detailed diagnostic info (disabled in production)
    for i, record in enumerate(records):
        logger.debug(
            f"Processing record {i}",
            extra={"record_id": record.get('id')}
        )

    # WARNING: Unexpected but handled
    empty_records = [r for r in records if not r.get('data')]
    if empty_records:
        logger.warning(
            "Empty records detected",
            extra={"empty_count": len(empty_records)}
        )

    # ERROR: Operation failed
    try:
        save_to_database(records)
    except Exception as e:
        logger.error(
            "Failed to save batch to database",
            extra={"batch_size": len(records), "error": str(e)},
            exc_info=True
        )
        raise

    # INFO: Operation completed
    logger.info(
        "Batch processing completed",
        extra={"records_processed": len(records)}
    )
```

---

### 3. Include Context and Correlation IDs

```python
import logging
import uuid
from contextvars import ContextVar

logger = logging.getLogger(__name__)

# Use contextvars for request/job tracking
request_id_var: ContextVar[str] = ContextVar('request_id', default=None)

class CorrelationIdFilter(logging.Filter):
    """Add correlation ID to all log records"""

    def filter(self, record):
        record.request_id = request_id_var.get() or "no-id"
        return True

# Setup logging with correlation ID filter
handler = logging.StreamHandler()
handler.addFilter(CorrelationIdFilter())
formatter = logging.Formatter(
    '%(asctime)s [%(request_id)s] %(levelname)s - %(message)s'
)
handler.setFormatter(formatter)

logger.addHandler(handler)
logger.setLevel(logging.INFO)

def process_job():
    """Every log in this job will have the same request_id"""
    # Set correlation ID for this job
    job_id = str(uuid.uuid4())
    request_id_var.set(job_id)

    logger.info("Job started")
    logger.info("Processing data")
    logger.info("Job completed")

# Output:
# 2025-10-16 10:30:45 [a1b2c3d4-...] INFO - Job started
# 2025-10-16 10:30:46 [a1b2c3d4-...] INFO - Processing data
# 2025-10-16 10:30:47 [a1b2c3d4-...] INFO - Job completed
```

---

### 4. Performance-Conscious Logging

```python
import logging

logger = logging.getLogger(__name__)

# ‚ùå Bad: Expensive operation even if DEBUG is disabled
logger.debug(f"Data: {expensive_serialization(large_object)}")

# ‚úÖ Good: Check log level first
if logger.isEnabledFor(logging.DEBUG):
    logger.debug(f"Data: {expensive_serialization(large_object)}")

# ‚úÖ Better: Use lazy evaluation
logger.debug("Data: %s", lambda: expensive_serialization(large_object))

# ‚úÖ Good: Sample logs in high-volume scenarios
import random

for i, record in enumerate(large_dataset):
    # Log every 1000th record
    if i % 1000 == 0:
        logger.info(f"Processed {i} records")

    # Or sample 1% of records
    if random.random() < 0.01:
        logger.debug(f"Processing record {i}", extra={"record": record})
```

---

## Monitoring and Alerting

### Logging Metrics for Monitoring

```python
import logging
import time
from dataclasses import dataclass
from typing import Optional

logger = logging.getLogger(__name__)

@dataclass
class PipelineMetrics:
    """Track pipeline metrics for monitoring"""
    job_id: str
    start_time: float
    rows_processed: int = 0
    errors: int = 0
    warnings: int = 0

    def log_metrics(self):
        """Log metrics in a monitoring-friendly format"""
        duration = time.time() - self.start_time

        logger.info(
            "Pipeline metrics",
            extra={
                "event": "pipeline_metrics",
                "job_id": self.job_id,
                "duration_seconds": round(duration, 2),
                "rows_processed": self.rows_processed,
                "errors": self.errors,
                "warnings": self.warnings,
                "throughput_rows_per_second": round(self.rows_processed / duration, 2)
            }
        )

# Usage with monitoring system
metrics = PipelineMetrics(job_id="etl-001", start_time=time.time())

try:
    for batch in process_batches():
        metrics.rows_processed += len(batch)

        if has_errors(batch):
            metrics.errors += 1

        if has_warnings(batch):
            metrics.warnings += 1

finally:
    # Always log metrics, even on failure
    metrics.log_metrics()
```

---

### Integration with Monitoring Platforms

```python
# CloudWatch Logs Example
import logging
import watchtower

# Setup CloudWatch handler
cloudwatch_handler = watchtower.CloudWatchLogHandler(
    log_group='/aws/ecs/data-pipeline',
    stream_name='etl-jobs'
)

logger = logging.getLogger()
logger.addHandler(cloudwatch_handler)
logger.setLevel(logging.INFO)

# Datadog Example
from datadog import initialize, statsd

initialize(api_key='your-key', app_key='your-app-key')

def log_with_metrics(message, metric_name, value):
    """Log and send metric to Datadog"""
    logger.info(message, extra={"metric": metric_name, "value": value})
    statsd.increment(metric_name, value)

# Usage
log_with_metrics(
    "Batch processed",
    metric_name="pipeline.rows_processed",
    value=1000
)
```

---

## Using Loguru - Modern Python Logging

### Why Loguru?

**Loguru advantages:**
- Simpler API than standard logging
- Structured logging by default
- Automatic context capture
- Better exception formatting
- Built-in rotation and retention

```python
from loguru import logger

# Remove default handler
logger.remove()

# Add structured JSON logging
logger.add(
    "logs/pipeline_{time:YYYY-MM-DD}.log",
    format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}",
    level="INFO",
    rotation="500 MB",      # Rotate at 500 MB
    retention="30 days",    # Keep for 30 days
    compression="zip",      # Compress rotated logs
    serialize=True          # Output as JSON
)

# Use it - simpler than standard logging!
logger.info("Pipeline started")
logger.info("Processing data", rows=10000, duration=45.2)
logger.error("API failed", error="Connection timeout", retries=3)

# Automatic exception tracking
try:
    risky_operation()
except Exception:
    logger.exception("Operation failed")  # Captures full traceback

# Context binding
pipeline_logger = logger.bind(job_id="etl-001", environment="production")
pipeline_logger.info("Step 1 complete")
pipeline_logger.info("Step 2 complete")
# All logs include job_id and environment
```

---

## üéØ Best Practices Summary

### Do's

‚úÖ **Use structured logging** - JSON format for production
‚úÖ **Include context** - Job IDs, customer IDs, batch numbers
‚úÖ **Log at appropriate levels** - INFO for milestones, DEBUG for details
‚úÖ **Add correlation IDs** - Track requests across systems
‚úÖ **Log metrics** - Row counts, durations, error rates
‚úÖ **Sanitize sensitive data** - Never log passwords, SSNs, etc.
‚úÖ **Configure rotation** - Don't fill up disk space
‚úÖ **Test your logs** - Ensure they're actually written

### Don'ts

‚ùå **Don't log in loops** - Too verbose, sample instead
‚ùå **Don't log sensitive data** - PII, credentials, secrets
‚ùå **Don't use print()** - Use proper logging
‚ùå **Don't ignore exceptions** - Always log errors
‚ùå **Don't log everything as ERROR** - Use appropriate levels
‚ùå **Don't forget log rotation** - Logs grow forever
‚ùå **Don't make logs unreadable** - Keep messages clear

---

## üîó Related Notes

- [[07. Testing Data Pipelines with Python|Chapter 7 - Testing]]
- [[04. Python Basics - Data Structures & Control Flow|Chapter 4 - Python Basics]]
- [[README|Project Overview]]

---

## üìö Key Takeaways

1. **Structured logging is essential** - JSON format enables querying and aggregation
2. **Context matters** - Include job IDs, timestamps, and relevant metadata
3. **Appropriate log levels** - DEBUG for development, INFO for production milestones
4. **Never log sensitive data** - Sanitize PII, credentials, and secrets
5. **Performance conscious** - Don't log in tight loops, sample instead
6. **Correlation IDs** - Track operations across distributed systems
7. **Log metrics** - Row counts, durations, throughput for monitoring
8. **Consider Loguru** - Simpler API with powerful features built-in

---

**Last Updated:** 2025-10-16
**Status:** ‚úÖ Complete
