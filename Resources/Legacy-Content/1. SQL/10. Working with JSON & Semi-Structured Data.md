---
title: Working with JSON & Semi-Structured Data
date: 2025-10-14
tags: [sql, json, jsonb, semi-structured, nested-data, arrays, data-engineering, modern-data]
status: active
learning_phase: "Modern Data (Semi-Structured)"
---

# Working with JSON & Semi-Structured Data

## Overview

Modern data engineering often involves semi-structured data like JSON. This guide covers SQL techniques for storing, querying, and transforming JSON data across different database platforms.

---

## JSON Data Types

### PostgreSQL

```sql
-- JSON: Text storage, slower
CREATE TABLE events (
    event_id INT,
    event_data JSON
);

-- JSONB: Binary storage, faster, indexable (recommended)
CREATE TABLE events (
    event_id INT,
    event_data JSONB
);
```

**JSONB vs JSON:**

| Feature | JSON | JSONB |
|---------|------|-------|
| **Storage** | Text | Binary |
| **Insert Speed** | Faster | Slightly slower |
| **Query Speed** | Slower | Much faster |
| **Indexing** | No | Yes (GIN) |
| **Operators** | Fewer | More |
| **Recommendation** | Use JSONB | ✅ |

### MySQL

```sql
-- JSON type (MySQL 5.7+)
CREATE TABLE products (
    product_id INT,
    attributes JSON
);
```

### SQL Server

```sql
-- No native JSON type, store as NVARCHAR
CREATE TABLE logs (
    log_id INT,
    log_data NVARCHAR(MAX)
);

-- Validate JSON
ALTER TABLE logs
ADD CONSTRAINT chk_json CHECK (ISJSON(log_data) = 1);
```

---

## Inserting JSON Data

### PostgreSQL

```sql
-- Insert JSON object
INSERT INTO events (event_id, event_data)
VALUES (1, '{"type": "click", "user_id": 123, "timestamp": "2024-01-15T10:30:00"}');

-- Insert JSONB with explicit cast
INSERT INTO events (event_id, event_data)
VALUES (2, '{"type": "purchase", "amount": 99.99}'::JSONB);

-- Insert from JSON function
INSERT INTO events (event_id, event_data)
VALUES (3, jsonb_build_object(
    'type', 'signup',
    'user_id', 456,
    'email', 'user@example.com'
));
```

### MySQL

```sql
-- Insert JSON
INSERT INTO products (product_id, attributes)
VALUES (1, '{"color": "red", "size": "M", "tags": ["sale", "popular"]}');

-- Insert using JSON functions
INSERT INTO products (product_id, attributes)
VALUES (2, JSON_OBJECT(
    'color', 'blue',
    'size', 'L',
    'in_stock', TRUE
));
```

---

## Querying JSON Data

### Extracting Values (PostgreSQL)

```sql
-- Extract as text with ->>
SELECT
    event_id,
    event_data->>'type' AS event_type,
    event_data->>'user_id' AS user_id
FROM events;

-- Extract as JSON with ->
SELECT
    event_id,
    event_data->'metadata' AS metadata_json
FROM events;

-- Nested extraction
SELECT
    event_data->'user'->>'name' AS user_name,
    event_data->'user'->>'email' AS user_email
FROM events;

-- Array element access
SELECT
    event_data->'tags'->>0 AS first_tag,
    event_data->'tags'->>1 AS second_tag
FROM events;
```

### Extracting Values (MySQL)

```sql
-- Extract with JSON_EXTRACT or ->
SELECT
    product_id,
    JSON_EXTRACT(attributes, '$.color') AS color,
    attributes->'$.size' AS size
FROM products;

-- Extract as unquoted string with ->>
SELECT
    product_id,
    attributes->>'$.color' AS color,
    JSON_UNQUOTE(JSON_EXTRACT(attributes, '$.color')) AS color_unquoted
FROM products;

-- Nested extraction
SELECT
    JSON_EXTRACT(attributes, '$.dimensions.height') AS height,
    attributes->'$.dimensions.width' AS width
FROM products;
```

### Extracting Values (SQL Server)

```sql
-- JSON_VALUE for scalar values
SELECT
    log_id,
    JSON_VALUE(log_data, '$.event_type') AS event_type,
    JSON_VALUE(log_data, '$.user_id') AS user_id
FROM logs;

-- JSON_QUERY for objects/arrays
SELECT
    log_id,
    JSON_QUERY(log_data, '$.metadata') AS metadata,
    JSON_QUERY(log_data, '$.tags') AS tags
FROM logs;
```

---

## Filtering JSON Data

### PostgreSQL

```sql
-- Filter by JSON field value
SELECT * FROM events
WHERE event_data->>'type' = 'purchase';

-- Filter by nested field
SELECT * FROM events
WHERE event_data->'user'->>'country' = 'USA';

-- Check if key exists
SELECT * FROM events
WHERE event_data ? 'user_id';

-- Check if any key exists
SELECT * FROM events
WHERE event_data ?| ARRAY['user_id', 'customer_id'];

-- Check if all keys exist
SELECT * FROM events
WHERE event_data ?& ARRAY['type', 'timestamp'];

-- Containment operator (@>)
SELECT * FROM events
WHERE event_data @> '{"type": "purchase"}';

-- Filter by array element
SELECT * FROM products
WHERE attributes->'tags' @> '["sale"]'::JSONB;
```

### MySQL

```sql
-- Filter by JSON field
SELECT * FROM products
WHERE attributes->>'$.color' = 'red';

-- JSON_CONTAINS
SELECT * FROM products
WHERE JSON_CONTAINS(attributes, '"sale"', '$.tags');

-- JSON_SEARCH (finds path to value)
SELECT * FROM products
WHERE JSON_SEARCH(attributes, 'one', 'red') IS NOT NULL;
```

---

## Modifying JSON Data

### PostgreSQL - Update JSON

```sql
-- Update entire JSON field
UPDATE events
SET event_data = '{"type": "updated", "timestamp": "2024-01-15T12:00:00"}'::JSONB
WHERE event_id = 1;

-- Update specific key (jsonb_set)
UPDATE events
SET event_data = jsonb_set(
    event_data,
    '{status}',
    '"completed"',
    true  -- create if doesn't exist
)
WHERE event_data->>'type' = 'purchase';

-- Update nested key
UPDATE events
SET event_data = jsonb_set(
    event_data,
    '{user, email}',
    '"newemail@example.com"'
)
WHERE event_id = 1;

-- Remove key
UPDATE events
SET event_data = event_data - 'temporary_field';

-- Add to array
UPDATE products
SET attributes = jsonb_set(
    attributes,
    '{tags}',
    (attributes->'tags') || '["new_tag"]'::JSONB
);
```

### MySQL - Update JSON

```sql
-- Update specific key
UPDATE products
SET attributes = JSON_SET(attributes, '$.color', 'green')
WHERE product_id = 1;

-- Insert if key doesn't exist
UPDATE products
SET attributes = JSON_INSERT(attributes, '$.new_field', 'value')
WHERE product_id = 1;

-- Replace only if key exists
UPDATE products
SET attributes = JSON_REPLACE(attributes, '$.color', 'blue')
WHERE product_id = 1;

-- Remove key
UPDATE products
SET attributes = JSON_REMOVE(attributes, '$.temporary_field')
WHERE product_id = 1;

-- Array append
UPDATE products
SET attributes = JSON_ARRAY_APPEND(attributes, '$.tags', 'new_tag')
WHERE product_id = 1;
```

---

## Working with JSON Arrays

### Expanding JSON Arrays to Rows

```sql
-- PostgreSQL: jsonb_array_elements
SELECT
    product_id,
    jsonb_array_elements(attributes->'tags') AS tag
FROM products;

-- With text extraction
SELECT
    product_id,
    jsonb_array_elements_text(attributes->'tags') AS tag
FROM products;

-- MySQL: JSON_TABLE (MySQL 8.0+)
SELECT
    product_id,
    tags.tag
FROM products,
JSON_TABLE(
    attributes,
    '$.tags[*]' COLUMNS (
        tag VARCHAR(50) PATH '$'
    )
) AS tags;

-- SQL Server: OPENJSON
SELECT
    p.product_id,
    t.value AS tag
FROM logs p
CROSS APPLY OPENJSON(p.log_data, '$.tags') t;
```

### Array Functions

```sql
-- PostgreSQL
-- Array length
SELECT
    product_id,
    jsonb_array_length(attributes->'tags') AS tag_count
FROM products;

-- Check if array contains value
SELECT * FROM products
WHERE attributes->'tags' @> '["sale"]'::JSONB;

-- MySQL
-- Array length
SELECT
    product_id,
    JSON_LENGTH(attributes, '$.tags') AS tag_count
FROM products;

-- Check if value in array
SELECT * FROM products
WHERE JSON_CONTAINS(attributes, '"sale"', '$.tags');
```

---

## JSON Aggregation

### PostgreSQL - Build JSON from Rows

```sql
-- Create JSON object from row
SELECT
    customer_id,
    jsonb_build_object(
        'name', name,
        'email', email,
        'signup_date', signup_date
    ) AS customer_json
FROM customers;

-- Aggregate rows to JSON array
SELECT
    jsonb_agg(
        jsonb_build_object(
            'product_id', product_id,
            'name', name,
            'price', price
        )
    ) AS products
FROM products
WHERE category = 'Electronics';

-- Aggregate to JSON object (key-value pairs)
SELECT
    jsonb_object_agg(product_id, name) AS products_map
FROM products;
```

### MySQL - Build JSON from Rows

```sql
-- Create JSON object
SELECT
    customer_id,
    JSON_OBJECT(
        'name', name,
        'email', email,
        'signup_date', signup_date
    ) AS customer_json
FROM customers;

-- Aggregate to JSON array
SELECT
    JSON_ARRAYAGG(
        JSON_OBJECT(
            'product_id', product_id,
            'name', name,
            'price', price
        )
    ) AS products
FROM products
WHERE category = 'Electronics';

-- Aggregate with JSON_OBJECTAGG
SELECT
    JSON_OBJECTAGG(product_id, name) AS products_map
FROM products;
```

---

## Indexing JSON Data

### PostgreSQL - GIN Indexes

```sql
-- Index entire JSONB column (supports @>, ?, ?&, ?| operators)
CREATE INDEX idx_events_data ON events USING GIN (event_data);

-- Query uses index
SELECT * FROM events
WHERE event_data @> '{"type": "purchase"}';

-- Index specific JSON path
CREATE INDEX idx_events_user_id ON events ((event_data->>'user_id'));

-- Query uses index
SELECT * FROM events
WHERE event_data->>'user_id' = '123';

-- Expression index for nested paths
CREATE INDEX idx_events_user_country ON events ((event_data->'user'->>'country'));
```

### MySQL - Generated Columns + Index

```sql
-- Create generated column
ALTER TABLE products
ADD COLUMN color VARCHAR(50) AS (attributes->>'$.color') STORED;

-- Index generated column
CREATE INDEX idx_products_color ON products(color);

-- Query uses index
SELECT * FROM products WHERE color = 'red';

-- Multi-valued index (MySQL 8.0.17+)
CREATE INDEX idx_products_tags ON products ((CAST(attributes->'$.tags' AS CHAR(50) ARRAY)));
```

---

## Schema Validation

### PostgreSQL - Check Constraints

```sql
-- Require specific keys
ALTER TABLE events
ADD CONSTRAINT chk_required_keys
CHECK (event_data ? 'type' AND event_data ? 'timestamp');

-- Validate value types
ALTER TABLE events
ADD CONSTRAINT chk_user_id_numeric
CHECK (
    event_data->>'user_id' IS NULL OR
    event_data->>'user_id' ~ '^[0-9]+$'
);
```

### MySQL - CHECK Constraints

```sql
-- Validate JSON structure
ALTER TABLE products
ADD CONSTRAINT chk_valid_json CHECK (JSON_VALID(attributes));

-- Require specific keys
ALTER TABLE products
ADD CONSTRAINT chk_required_keys
CHECK (JSON_CONTAINS_PATH(attributes, 'all', '$.color', '$.size'));
```

---

## Common JSON Patterns

### Pattern 1: Flatten Nested JSON

```sql
-- PostgreSQL
SELECT
    event_id,
    event_data->>'type' AS event_type,
    event_data->'user'->>'id' AS user_id,
    event_data->'user'->>'name' AS user_name,
    event_data->'metadata'->>'source' AS source,
    (event_data->'amount')::NUMERIC AS amount
FROM events;
```

### Pattern 2: Merge JSON Objects

```sql
-- PostgreSQL: Merge two JSON objects
SELECT
    event_data || '{"processed": true, "processed_at": "2024-01-15T12:00:00"}'::JSONB AS updated_data
FROM events;

-- MySQL: JSON_MERGE_PATCH
SELECT
    JSON_MERGE_PATCH(
        attributes,
        '{"processed": true, "processed_at": "2024-01-15T12:00:00"}'
    ) AS updated_attributes
FROM products;
```

### Pattern 3: Extract JSON to Table

```sql
-- PostgreSQL: Create table from JSON
CREATE TABLE customers_extracted AS
SELECT
    (event_data->>'user_id')::INT AS user_id,
    event_data->'user'->>'name' AS name,
    event_data->'user'->>'email' AS email,
    (event_data->>'created_at')::TIMESTAMP AS created_at
FROM events
WHERE event_data->>'type' = 'user_created';
```

### Pattern 4: Transform Arrays

```sql
-- PostgreSQL: Filter and transform JSON array
SELECT
    product_id,
    jsonb_agg(tag)
        FILTER (WHERE tag->>'active' = 'true') AS active_tags
FROM products,
    jsonb_array_elements(attributes->'tags') AS tag
GROUP BY product_id;
```

### Pattern 5: Nested Aggregation

```sql
-- PostgreSQL: Create nested JSON structure
SELECT
    customer_id,
    jsonb_build_object(
        'customer', jsonb_build_object(
            'id', c.customer_id,
            'name', c.name
        ),
        'orders', (
            SELECT jsonb_agg(
                jsonb_build_object(
                    'order_id', o.order_id,
                    'amount', o.total_amount,
                    'date', o.order_date
                )
            )
            FROM orders o
            WHERE o.customer_id = c.customer_id
        )
    ) AS customer_with_orders
FROM customers c;
```

---

## Performance Considerations

### Best Practices for JSON

```sql
-- ✅ GOOD: Extract and index frequently queried fields
ALTER TABLE events
ADD COLUMN event_type VARCHAR(50) AS (event_data->>'type') STORED;

CREATE INDEX idx_events_type ON events(event_type);

-- ✅ GOOD: Use JSONB (PostgreSQL) for better performance
-- ✅ GOOD: Create GIN index on JSONB columns
CREATE INDEX idx_events_data_gin ON events USING GIN (event_data);

-- ❌ BAD: Don't use JSON for highly relational data
-- Store in normalized tables instead

-- ❌ BAD: Don't store large blobs in JSON
-- Use separate BLOB storage
```

---

## When to Use JSON

### ✅ Good Use Cases

1. **Schema flexibility** - Evolving/unknown schema
2. **API responses** - Store entire API payload
3. **User preferences** - Variable settings per user
4. **Metadata** - Additional optional attributes
5. **Event logging** - Flexible event structure
6. **Product attributes** - Variable properties per product

### ❌ Poor Use Cases

1. **Highly relational data** - Use proper tables/joins
2. **Frequent complex queries** - Extract to columns
3. **Data integrity critical** - Use constraints on tables
4. **Large volumes** - Normalize for performance
5. **Fixed schema** - Use regular columns

---

## Migration: JSON to Relational

```sql
-- Extract JSON to normalized tables
CREATE TABLE orders_extracted AS
SELECT
    (order_data->>'order_id')::INT AS order_id,
    (order_data->>'customer_id')::INT AS customer_id,
    (order_data->>'total_amount')::DECIMAL(10,2) AS total_amount,
    (order_data->>'order_date')::DATE AS order_date
FROM orders_json;

-- Extract nested array to separate table
CREATE TABLE order_items_extracted AS
SELECT
    (order_data->>'order_id')::INT AS order_id,
    (item->>'product_id')::INT AS product_id,
    (item->>'quantity')::INT AS quantity,
    (item->>'price')::DECIMAL(10,2) AS price
FROM orders_json,
    jsonb_array_elements(order_data->'items') AS item;
```

---

## Best Practices Summary

### ✅ Do's

1. **Use JSONB in PostgreSQL** (not JSON)
2. **Index frequently queried paths** (GIN or expression indexes)
3. **Extract critical fields** to regular columns
4. **Validate JSON structure** with constraints
5. **Use JSON for flexible schemas** (metadata, settings)
6. **Aggregate to JSON** for API responses
7. **Profile JSON queries** (EXPLAIN ANALYZE)

### ❌ Don'ts

1. **Don't use JSON for relational data**
2. **Don't store large payloads** in JSON columns
3. **Don't over-nest** - Keep JSON structure simple
4. **Don't forget to index** JSON paths used in WHERE
5. **Don't ignore data types** when extracting
6. **Don't use JSON** when regular columns suffice

---

## Quick Reference

```
OPERATION            POSTGRESQL                      MYSQL
────────────────────────────────────────────────────────────────────
Extract value        data->>'key'                   data->>'$.key'
Extract object       data->'key'                    data->'$.key'
Nested access        data->'a'->'b'->>'c'          data->'$.a.b.c'
Array element        data->'arr'->>0               data->'$.arr[0]'
Check key exists     data ? 'key'                  JSON_CONTAINS_PATH()
Contains value       data @> '{"k":"v"}'           JSON_CONTAINS()
Update field         jsonb_set()                   JSON_SET()
Build object         jsonb_build_object()          JSON_OBJECT()
Aggregate            jsonb_agg()                   JSON_ARRAYAGG()
Array elements       jsonb_array_elements()        JSON_TABLE()
Index type           GIN index                     Generated column + index
```

---

## Related Concepts

- [[Data Definition Language (DDL)]] - Creating JSON columns
- [[String Manipulation & Pattern Matching]] - Text processing
- [[Data Quality & Validation]] - JSON validation
- [[Query Optimization Techniques]] - JSON indexing

---

## Key Takeaways

1. **JSONB > JSON** in PostgreSQL for performance
2. **Index JSON paths** frequently used in WHERE clauses
3. **Extract critical fields** to regular columns for better queries
4. **Use JSON for flexibility**, relational tables for structure
5. **GIN indexes** enable efficient JSONB queries
6. **JSON aggregation** builds API responses efficiently
7. **Validate JSON structure** with constraints
8. **Profile JSON queries** - They can be slower than regular columns
